\section{Discussion}\label{sec:discussion}

Before getting into the discussion, it would be beneficial to give a reader's note regarding the terminology. As outlined in Methodology, the mathematical formulas the agents use for their decision, signaling and updating processes are meant to get the most favourable outcome for that individual agent in particular. Essentially, they are ``greedy" algorithms that intend to maximise the agent score. In this study, we are more focused on the outcome and the score distribution of agents, and hope to measure how drastic the difference between scores of different orders of ToM agents to determine how ``fairly distributed" the end results are. In this and the following section, we will refer to strategies as ``cooperative" when they end up with more fairly distributed end results with less score difference between orders compared to the default equal population, while we will refer to strategies as ``greedy" when they result in more skewed score distributions with similar or more score difference between the orders compared to the default equal population.

\subsection{The Regular Simulation}

In the regular simulation, it is seen that including the default equal population, in 6 out of 7 tested scenarios, agents perform better with a higher order ToM with the first order agents performing better than zero order agents and second order agents performing better than the first order agents. 

The only exception is the $150_{0}$/$75_{1}$/$75_{2}$ scenario, in which there are $50\%$ more zero order agents than the default equal population. In this scenario, the first order agents perform better than the second order agents but also this is the scenario with the highest total score across all three orders of ToM. This is because while second order agents can adapt to a zero order dominant population, first order agents are ready for it and benefit from it from the beginning. This is evident in all the other scenarios too, as the first order score is directy correlated with the number of zero order agents. 

The second order agents are not as sensitive to population changes, but they also prefer more zero order agents than more first order agents, with them having higher AOAS in scenarios with more zero order agents.

These results indicate that without signaling, unless there is a significant (around $50\%$) increase in the number of zero order agents, higher order agents, in general, perform better than lower order agents (with the highest order being 2). The average agent score (across all orders) for 300 agents and 1000 epochs is $\mathbf{63.115}$ for the default equal population, and $\mathbf{78.517}$ for the $150_{0}$/$75_{1}$/$75_{2}$ scenario, which has the highest average.

\subsection{The Signaling Simulation}

In the signaling simulation, the picture is not too different from the regular simulation if analysed from an order-wise perspective. In all of the scenarios, the first order agents collectively perform better than zero order agents, and second order agents collectively perform better than first order agents, with no exceptions. This is expected, as also seen in the regular simulation and in previous work, higher order agents perform better than lower order agents, with the highest order being the second.

The main difference between the regular and signaling simulations is the score differences. In the regular simulation, in all scenarios, at least one of the score differences (either $\mathbf{sd^0_1}$ or $\mathbf{sd^1_2}$) is higher than $\mathbf{48}$ whereas in the signaling simulation, in 8 out of 9 scenarios, both score differences are lower than $\mathbf{48}$. The only exception is the $60_{s_{0}}/60_{s_{1}}/30_{s_{2}}/60_{r_{0}}/60_{r_{1}}/30_{r_{2}}$ scenario where $\mathbf{sd^0_1 = 48.621}$. This indicates a more balanced distribution of scores between the orders of ToM in the signaling simulation, from a higher, order-wise perspective.

The average agent score (across all orders) for 300 agents and 1000 epochs is $\mathbf{38.197}$ for the default equal population, and $\mathbf{43.684}$ for the $60_{s_{0}}/60_{s_{1}}/30_{s_{2}}/60_{r_{0}}/60_{r_{1}}/30_{r_{2}}$ scenario, which has the highest average. Both of these scores are lower than their counterparts in the regular simulation, which is expected as the signaling simulation is a more difficult task for the agents that contains more than one dimension of learning. While this may also be attributed to the fact that the signaling simulation is simply detrimental to the agents, the fact that the score distribution between the orders of ToM is more balanced in the signaling simulation indicates that the resulting environment and the behavior caused by that environment is not "worse" than the regular simulation, but rather different and more complex.

In fact, when the results of the signaling and receiving agents are compared in-order, it is seen that the receiving agents perform better than the signaling agents in all scenarios, except for zero order agents, whose behaviour is not as affected by the signaling/receiving distinction. Before the experimentation process started, we hypothesized that the signaling agents would learn how the receiving agents respond to their signals and would adapt to that in a greedy manner, and would earn higher scores than the receiving agents. However, the results show that the receiving agents perform better than the signaling agents, which indicates that the receiving agents are able to adapt to the signaling agents' signals and respond to them in a way that is more beneficial to them than the signaling agents. This phenomenon can be explained by the processing order of the agents, as the receiving agents process the signals after the signaling agents signal them, in which case a simulation with asynchronous processing could be the topic of future work. If the same results are observed in an asynchronous simulation, then it would be safe to say that the receiving agents are more advantageous than the signaling agents in the signaling simulation. Another possible contributing reason is that while receiving agents process all the signals transmitted and update accordingly, the signaling agents only take their signal into consideration. This again could be addressed in future work along with the zero order signaling agent update process, which could have also contributed to this phenomenon.

Inspecting the results further, one can see that in 6 out of 9 scenarios, the first order receiving agents perform the best, with the second order receiving agents performing the best in the remaining 3 scenarios. This is quite interesting, as both in the regular and signaling simulation the second order agents have better overall scores than first order agents. This could suggest that for receiving agents, the "higher order ToM advantage" starts and ends at the first order, and the scores for even higher orders of ToM than tested (3, 4, etc.) would be lower than the scores of the previous order. This, once again could be explored in future work.

Like in the regular simulation, more zero order agents mean more score for the other orders, and the reverse, but this time, the second order agents are more sensitive to the number of zero order agents than the first order agents. This is evident in the difference between second order scores in the default equal population and the $75_{s_{0}}/37_{s_{1}}/37_{s_{2}}/75_{r_{0}}/38_{r_{1}}/38_{r_{2}}$ scenario, which is higher than the difference in first order agent scores. An increased number of first order agents benefits only the first order agents and does not have visible significant effect on other order scores while the opposite situation has the opposite effect on first order agents and once again, no visible significant effect on other order scores. Looking at the second order over/under-abundance scenarios, it can be seen that the second order agents decrease all order agent scores when there's more of them, and increase all order agent scores when there's less of them. This is the opposite of the first order agents, which increase all order agent scores when there's more of them, and decrease all order agent scores when there's less of them. These last two claims exclude the zero order agents, as they are not as affected by the number of other order agents as the other orders are. This is also evident in the regular simulation, where the zero order agents are not as affected by the number of other order agents as the other orders are.

The situation with the signaling/receiving over-abundance scenarios is quite peculiar. An over-abundance of signaling agents benefit every agent group except first order signaling agents which have a lower score, while and ober-abundance of signaling agents benefits only the first order signaling and second order receiving agents, with the rest having lower scores than the default equal population. This suggests 3 main things:

\begin{itemize}
    \item Our previous suggestion about receiving agents employing a greedy strategy hold up, as more of them means worse or equal scores for all agent groups except second order receiving agents.
    \item More signaling agents means better scores for all agent groups except first order signaling agents, which suggests that they might not employ a greedy strategy but rather a cooperative one, which is beneficial to all agent groups.
    \item First order signaling agent behaviour is unexpected and should be explored further, could maybe have been caused by wrong formulation or implementation of the agents.
\end{itemize}

Overall, when we compare the signaling simulation results with the regular simulation results, we can see that the signaling simulation is a more complex task for the agents, as the overall average AOAS lower in the signaling simulation than in the regular simulation. However, the score distribution between the orders of ToM is more balanced in the signaling simulation, which indicates that the resulting environment and the behavior caused by that environment is not ``worse" (in terms of cooperation and collective gains, which are indicated by the score differences) than the regular simulation, but rather different and more complex. The results with more even distribution of scores between the orders of ToM could both be attributed to the fact that because it is a more complex task, it is harder to employ a greedy strategy, but also to the fact that the agents are able to employ cooperative or semi-cooperative strategies due to the added dimension of cost-free communication. 