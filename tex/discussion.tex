\section{Discussion}\label{sec:discussion}

\subsection{The Regular Simulation}

In the regular simulation, it is seen that including the default equal population, in 6 out of 7 tested scenarios, agents perform better with a higher order ToM with the first order agents performing better than zero order agents and second order agents performing better than the first order agents. 

The only exception is the $150_{0}$/$75_{1}$/$75_{2}$ scenario, in which there are $50\%$ more zero order agents than the default equal population. In this scenario, the first order agents perform better than the second order agents but also this is the scenario with the highest total score across all three orders of ToM. This is because while second order agents can adapt to a zero order dominant population, first order agents are ready for it and benefit from it from the beginning. This is evident in all the other scenarios too, as the first order score is directy correlated with the number of zero order agents. 

The second order agents are not as sensitive to population changes, but they also prefer more zero order agents than more first order agents, with them having higher AOAS in scenarios with more zero order agents.

These results indicate that without signaling, unless there is a significant (around $50\%$) increase in the number of zero order agents, higher order agents, in general, perform better than lower order agents (with the highest order being 2). The average agent score (across all orders) for 300 agents and 1000 epochs is $\mathbf{63.115}$ for the default equal population, and $\mathbf{78.517}$ for the $150_{0}$/$75_{1}$/$75_{2}$ scenario, which has the highest average.

\subsection{The Signaling Simulation}

In the signaling simulation, the picture is not too different from the regular simulation if analysed from an order-wise perspective. In all of the scenarios, the first order agents collectively perform better than zero order agents, and second order agents collectively perform better than first order agents, with no exceptions. This is expected, as also seen in the regular simulation and in previous work, higher order agents perform better than lower order agents, with the highest order being the second.

The main difference between the regular and signaling simulations is the score differences. In the regular simulation, in all scenarios, at least one of the score differences (either $\mathbf{sd^0_1}$ or $\mathbf{sd^1_2}$) is higher than $\mathbf{48}$ whereas in the signaling simulation, in 8 out of 9 scenarios, both score differences are lower than $\mathbf{48}$. The only exception is the $60_{s_{0}}/60_{s_{1}}/30_{s_{2}}/60_{r_{0}}/60_{r_{1}}/30_{r_{2}}$ scenario where $\mathbf{sd^0_1 = 48.621}$. This indicates a more balanced distribution of scores between the orders of ToM in the signaling simulation, from a higher, order-wise perspective.

The average agent score (across all orders) for 300 agents and 1000 epochs is $\mathbf{38.197}$ for the default equal population, and $\mathbf{43.684}$ for the $60_{s_{0}}/60_{s_{1}}/30_{s_{2}}/60_{r_{0}}/60_{r_{1}}/30_{r_{2}}$ scenario, which has the highest average. Both of these scores are lower than their counterparts in the regular simulation, which is expected as the signaling simulation is a more difficult task for the agents that contains more than one dimension of learning. While this may also be attributed to the fact that the signaling simulation is simply detrimental to the agents, the fact that the score distribution between the orders of ToM is more balanced in the signaling simulation indicates that the resulting environment and the behavior caused by that environment is not "worse" than the regular simulation, but rather different and more complex.

In fact, when the results of the signaling and receiving agents are compared in-order, it is seen that the receiving agents perform better than the signaling agents in all scenarios, except for zero order agents, whose behaviour is not as affected by the signaling/receiving distinction. Before the experimentation process started, we hypothesized that the signaling agents would learn how the receiving agents respond to their signals and would adapt to that in a greedy manner, and would earn higher scores than the receiving agents. However, the results show that the receiving agents perform better than the signaling agents, which indicates that the receiving agents are able to adapt to the signaling agents' signals and respond to them in a way that is more beneficial to them than the signaling agents. This phenomenon can be explained by the processing order of the agents, as the receiving agents process the signals after the signaling agents signal them, in which case a simulation with asynchronous processing could be the topic of future work. If the same results are observed in an asynchronous simulation, then it would be safe to say that the receiving agents are more advantageous than the signaling agents in the signaling simulation.

Inspecting the results further, one can see that in 6 out of 9 scenarios, the first order receiving agents perform the best, with the second order receiving agents performing the best in the remaining 3 scenarios. This is quite interesting, as both in the regular and signaling simulation the second order agents have better overall scores than first order agents. This could suggest that for receiving agents, the "higher order ToM advantage" starts and ends at the first order, and the scores for even higher orders of ToM than tested (3, 4, etc.) would be lower than the scores of the previous order. This, once again could be explored in future work.

Like in the regular simulation, more zero order agents mean more score for the other orders, and the reverse, but this time, the second order agents are more sensitive to the number of zero order agents than the first order agents. This is evident in the difference between second order scores in the default equal population and the $75_{s_{0}}/37_{s_{1}}/37_{s_{2}}/75_{r_{0}}/38_{r_{1}}/38_{r_{2}}$ scenario, which is higher than the difference in first order agent scores. An increased number of first order agents benefits only the first order agents and does not have visible significant effect on other order scores while the opposite situation has the opposite effect on first order agents and once again, no visible significant effect on other order scores. Looking at the second order over/under-abundance scenarios, it can be seen that the second order agents decrease all order agent scores when there's more of them, and increase all order agent scores when there's less of them. This is the opposite of the first order agents, which increase all order agent scores when there's more of them, and decrease all order agent scores when there's less of them. These last two claims exclude the zero order agents, as they are not as affected by the number of other order agents as the other orders are. This is also evident in the regular simulation, where the zero order agents are not as affected by the number of other order agents as the other orders are.

The situation with the signaling/receiving over-abundance scenarios is quite peculiar. An over-abundance of signaling agents benefit every agent group except first order signaling agents which have a lower score, while and ober-abundance of signaling agents benefits only the first order signaling and second order receiving agents, with the rest having lower scores than the default equal population. This suggests 3 main things:

\begin{itemize}
    \item Our previous suggestion about receiving agents employing a greedy strategy hold up, as more of them means worse or equal scores for all agent groups except second order receiving agents, which should be the most effective receiving agents, in theory.
    \item More signaling agents means better scores for all agent groups except first order signaling agents, which suggests that they might not employ a freedy strategy but rather a cooperative one, which is beneficial to all agent groups.
    \item First order signaling agent behaviour is unexpected and should be explored further, could maybe have been caused by wrong formulation or implementation of the agents.
\end{itemize}