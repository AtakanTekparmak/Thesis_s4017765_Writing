In the signaling simulation, the agents are divided into two groups: the signaling agents and the receiving agents. The signaling agents can signal any action (a number in the range $[0,22]$) to the receiving agents, on top of the ability to decide. The receiving agents can process transmitted signals from the signaling agents before deciding. There are five different processes performed in each round. In order, they are:

\begin{enumerate}
    \item The signaling agents decide on a signal and transmit it
    \item The receiving agents receive the signal and process it
    \item All agents decide on an action
    \item The agent scores are updated  
    \item The agent beliefs are updated
\end{enumerate}

Even though not mentioned in the itemized list above, the decision and update processes for signaling and receving agents are different. They do resemble in certain aspects as similar learning algorithms were used for conistency, but the differences are significant enough to warrant a separate explanation, which will be done in the following subsections.

\subsubsection{Signaling Agents}

All signaling agents employ a 2-dimensional beliefs array of the shape (23,23), in which the first dimension represents and holds information for signals, and the second dimension represents and holds information for actions given the signal. In the decision process for all signaling agents, the agent uses the sub-array of shape (23,1), indexed by the signal, to decide on an action. How each order of ToM deals with the signal, decision and update processes are explained in the following sections.

\subsubsubsection{2.2.1.1}{Zero Order Signaling Agent}

The zero order agent employs a simple greedy strategy for signaling and deciding. In both of them, the belief vector $\mathbf{b_{\zeta}}$ is used, where: 

\[
\mathbf{b_{\zeta}} = [[b_{\zeta_{0_{0}}}, \ldots, b_{\zeta_{0_{22}}}], \ldots, [b_{\zeta_{22_{0}}}, \ldots, b_{\zeta_{22_{22}}}]]
\]

The \textbf{signal} $\mathbf{\phi}$ and the \textbf{decision} $\mathbf{d_0}$, which is chosen by the agent using the signal $\mathbf{\phi}$ is given by: 

\begin{equation*}
\label{eq:zero-order-signal}
\label{eq:zero-order-decide}
\begin{aligned}
    \phi = \arg\max_s \sum_{i=0}^{22} b_{\zeta_i}, \quad i = 0, 1, \ldots, 22. \\
    d_0 = \arg\max_d b_{\zeta_{\phi_d}}, \quad d = 0, 1, \ldots, 22.
\end{aligned}
\end{equation*}

The agent decides whether or not to \textbf{update} for action $\mathbf{a}$ as follows: 

\begin{equation}
\text{{update}}(a) \rightarrow \begin{cases}
\text{{yes}}, & \text{{if }} d_0 = (a + 1) \mod 23 \\
\text{{no}}, & \text{{otherwise}}
\end{cases}
\end{equation}

After that, the update process is the same as the \hyperref[eq:zero-order-update]{Non-signaling Zero Order Agent}, with the only difference being instead of $\mathbf{b}$, the sub-vector $\mathbf{b_{s^0}}$ is used.

\subsubsubsection{2.2.1.2}{First Order Signaling Agent}

The first order agent employs a similar but slightly different strategy for signaling and deciding. In both of them, the same belief vector $\mathbf{b}$ is used. The agent also has a zero order agent model $\mathbf{m^0}$, whose \textbf{signal} $\mathbf{s^0}$ (calculations given in \hyperref[eq:zero-order-signal]{Equation 2.1}) is used in the  signaling process. The \textbf{signal} $\mathbf{s^1}$ and the \textbf{decision} $\mathbf{d_1}$ chosen by the agent is given by:

\begin{equation*}
\begin{aligned}
    s^1 = \begin{cases}
        \text{{random\_choice()}}, & \text{{if }} \text{{check\_epsilon()}} \\
        s^0, & \text{{otherwise}}
    \end{cases} \\
    d_1 = \arg\max_d b_{{s^1}_d}, \quad d = 0, 1, \ldots, 22. \qquad
\end{aligned}
\end{equation*}

The \textbf{update} process is the same as the \hyperref[eq:zero-order-update]{Non-signaling Zero Order Agent}, with the only difference being instead of $\mathbf{b}$, the sub-vector $\mathbf{b_{s^1}}$ is used.

\subsubsubsection{2.2.1.2}{Second Order Signaling Agent}

The second order signaling agent is a lot like a regular second order agent, with the lower order signaling agent models $\mathbf{m^0}$ and $\mathbf{m^1}$, and the order beliefs $\mathbf{b_o}$. The \textbf{decide} and \textbf{update} processes are the same as the \hyperref[eq:second-order-decide]{Non-signaling Second Order Agent}, with the only difference being the extra \textbf{signal} $\mathbf{s^2}$ chosen by the agent, given by the same algorithm for \textbf{decide}, but without the modulo operation on the lower order signal $\mathbf{s_l}$.

\subsubsection{Receiving Agents}

The receiving agents make use of two different sets of beliefs, one 1-dimensional and one 2-dimensional. The 1-dimensional beliefs array of the shape (23,1) is used to process the incoming signals, and the 2-dimensional beliefs array of the shape (23,23) is used to decide on an action according to the current beliefs formulated through received signals. How each order of ToM deals with the processing the signal, decision and update processes are explained in the following subsections.

\subsubsubsection{2.2.2.1}{Zero Order Receiving Agent}

The zero order receiving agent employs a simple greedy strategy for processing the signal and deciding. In the \textbf{process\_signal} process, the agent uses the the belief vector $\mathbf{b_s}$, where:

\[
\mathbf{b_s} = [b_{0}, b_{1}, \ldots, b_{22}]
\]

on this vector, which is re-initialised every round, the agent performs the same \textbf{update} process as the \hyperref[eq:zero-order-update]{Non-signaling Zero Order Agent}, with the only difference being instead of $\mathbf{b}$, the vector $\mathbf{b_s}$ is used. For the decide and update processes the connected beliefs vector $\mathbf{b_c}$ is used, where:

\[
\mathbf{b_c} = [[b_{c_{0_{0}}}, b_{c_{0_{1}}}, \ldots, b_{c_{0_{22}}}], \ldots, [b_{c_{22_{0}}}, b_{c_{22_{1}}}, \ldots, b_{c_{22_{22}}}]]
\]

The \textbf{decide} process is given by, where $\psi$ represents the zero order signal belief for the round:

\begin{equation*}
\begin{aligned}
    \psi = \arg\max_s b_{s_i}, \quad i = 0, 1, \ldots, 22. \\
    d_0 = \arg\max_d b_{c_{{\psi}_d}}, \quad d = 0, 1, \ldots, 22.
\end{aligned}
\end{equation*}

The \textbf{update} process is the same as the \hyperref[eq:zero-order-update]{Non-signaling Zero Order Agent}, with the difference being that the connected beliefs vector $\mathbf{b_c}$ is used instead of $\mathbf{b}$, and instead of the final calculation:

\[
    b_{a_j} = b_{a_j} + LEARNING\_SPEED 
\]

the following calculation is used:

\begin{equation*}
    b_{c_{\psi_{a_j}}} = b_{c_{\psi_{a_j}}} + LEARNING\_SPEED
\end{equation*}

where $a_j$ represents an action from the actions list for that round.

\subsubsubsection{2.2.2.2}{First Order Receiving Agent}

The first order receiving agent is a lot like the non-signalling first order agent, in the sense that it simply uses a model of a zero order agent to operate, with the sole addition of having a \textbf{process\_signal} process, where the \textvf{process\_signal} process of the zero order agent is called. This agent is essentially a superset of the non-signaling first order agent, with the extra ability to process signals.

\subsubsubsection{2.2.2.3}{Second Order Receiving Agent}

The second order receiving agent is also almost identical the non-signaling second order agent, with only the extra \textbf{process\_signal} process, in which the \textbf{process\_signal} process of the zero and first order agents are called. This agent is also essentially a superset of the non-signaling second order agent, with the extra ability to process signals.

\subsubsection{Simulation}

The signaling simulation will have a total of 11 different initial population configurations to be simulated. These population configurations are chosen specifically because for each ToM order it again investigates the effects listed for the signaling simulation, but also the effects of scenarios in which there are more signaling agents than receiving agents, and vice versa, based on the default order population of the simulation (i.e. the first row of \hyperref[tab:reg-population-table]{Table 2.1}). The ratio of difference for the scenarios with more signaling agents than receiving agents is 30:70 and for the scenarios with more receiving agents it's 70:30. The population configurations are like described below:

\begin{itemize}
    \item Order-wise, the initial 7 scenarios from \hyperref[tab:reg-population-table]{Table 2.1} are exactly the same, with each order being divided into half for signaling and receiving agents.
    \item The other 4 scenarios are with the order configuration of $\{33,33,33\}$ but with the signaling agents being 70\% and 90\% of the population and the receiving agents being 30\% and 10\% of the population, and vice versa.
\end{itemize}


Throughout the simulation, the behavior of the agents will be observed and recorded. This data will include the signals sent by the signaling agents, the actions chosen by all agents, and the payoffs received by each agent. The data will be analyzed, for each simulation individually but also inter-simulation, to determine how the inclusion of signaling in the Mod Game affects the behavior of Theory of Mind agents. The results will be compared to the findings of \cite{de2013much} and \cite{veltman2019training} to evaluate the effect on signaling on emergent agent behaviour.